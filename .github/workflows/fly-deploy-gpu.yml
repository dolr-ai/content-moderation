# See https://fly.io/docs/app-guides/continuous-deployment-with-github-actions/

name: Fly Deploy GPU
on:
  push:
    branches:
      - benchmark
  workflow_dispatch: {}

jobs:
  deploy:
    name: Deploy GPU app
    runs-on: ubuntu-latest
    concurrency: deploy-group-gpu
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive
      - uses: superfly/flyctl-actions/setup-flyctl@master

      # Set Fly secrets
      - name: Set Fly secrets
        run: |
          flyctl secrets set --stage --app "stage-content-moderation-server-gpu" HF_TOKEN="$HF_TOKEN"
          flyctl secrets set --stage --app "stage-content-moderation-server-gpu" GCP_CREDENTIALS="$GCP_CREDENTIALS"
          flyctl secrets set --stage --app "stage-content-moderation-server-gpu" GCS_BUCKET="$GCS_BUCKET"
          flyctl secrets set --stage --app "stage-content-moderation-server-gpu" GCS_EMBEDDINGS_PATH="$GCS_EMBEDDINGS_PATH"
          flyctl secrets set --stage --app "stage-content-moderation-server-gpu" GCS_PROMPT_PATH="$GCS_PROMPT_PATH"
        env:
          # todo: use org HF_TOKEN later currently using personal token
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          FLY_API_TOKEN: ${{ secrets.FLY_IO_DEPLOY_TOKEN }}
          GCP_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          GCS_EMBEDDINGS_PATH: ${{ secrets.GCS_EMBEDDINGS_PATH }}
          GCS_PROMPT_PATH: ${{ secrets.GCS_PROMPT_PATH }}

      - name: check fly secrets
        run: |
          flyctl secrets list --app stage-content-moderation-server-gpu
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_IO_DEPLOY_TOKEN }}

      # Check fly status
      - name: Check fly status
        run: |
          flyctl status --app stage-content-moderation-server-gpu
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_IO_DEPLOY_TOKEN }}

      # Deploy to Fly
      - name: Deploy a docker container to fly.io
        run: flyctl deploy --remote-only --config src_deploy/gpu.fly.toml --dockerfile ./src_deploy/gpu.Dockerfile
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_IO_DEPLOY_TOKEN }}

      # Wait for deployment to complete
      - name: Wait for deployment to stabilize
        run: sleep 60

      # Comprehensive GPU verification
      - name: Verify GPU setup on deployed instance
        run: |
          echo "Running GPU verification checks on deployed instance..."

          # Check NVIDIA driver and CUDA
          echo "=== NVIDIA DRIVER INFO ==="
          flyctl ssh console --app stage-content-moderation-server-gpu -C "nvidia-smi"

          echo "=== CUDA LIBRARIES ==="
          flyctl ssh console --app stage-content-moderation-server-gpu -C "ldconfig -p | grep -E 'libcuda|libcudart|libnvidia'"

          echo "=== TORCH CUDA INFO ==="
          flyctl ssh console --app stage-content-moderation-server-gpu -C "python -c 'import torch; print(f\"CUDA available: {torch.cuda.is_available()}\"); print(f\"CUDA version: {torch.version.cuda}\"); print(f\"GPU count: {torch.cuda.device_count()}\"); print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}\")');"

          # Run our full GPU check script
          echo "=== RUNNING FULL GPU CHECK ==="
          flyctl ssh console --app stage-content-moderation-server-gpu -C "python /app/check_gpu.py"

          echo "GPU verification complete"
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_IO_DEPLOY_TOKEN }}

