This repository contains a collection of notebooks for benchmarking LLMs and other AI models for content moderation.

## Setup

```bash
pip install -r requirements.txt
```


## Configuration
Use `dev_config.yml` to configure the environment refer `template_dev_config.yml` for more details.


## References

[Introducing v0.5 of the AI Safety Benchmark from MLCommons](https://arxiv.org/pdf/2404.12241)